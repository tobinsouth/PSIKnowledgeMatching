{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "DATASET = \"quora\"\n",
    "sbert_model_name = \"msmarco-distilbert-base-tas-b\"\n",
    "device = \"cpu\" # cuda for gpu usage\n",
    "k_queries = 5000\n",
    "k_documents = 261465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/tsouth/.local/lib/python3.10/site-packages/beir/util.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2024-04-26 20:21:52.177676: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-26 20:21:52.178511: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-26 20:21:52.204896: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-26 20:21:55.929191: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 20:22:30.996025: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from time import time\n",
    "from beir import util\n",
    "from beir_reengineered import NewSentenceBERT\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "import os, json, random\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2. (only sometimes) round embeddings\n",
    "from beir.retrieval.search import BaseSearch # type: ignore beir/retrieval/search/dense/exact_search.py\n",
    "from beir.util import cos_sim\n",
    "import torch # type: ignore\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import heapq\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExperiementRetrievalExactSearch is parent class for any model we are using for our experiement that can be used for retrieval\n",
    "# Abstract class is BaseSearch\n",
    "class ExperiementRetrievalExactSearch(BaseSearch):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            path_corpus_embeddings: str = \"datasets/subquora/corpus_embeddings.pkl\",\n",
    "            path_query_embeddings: str = \"datasets/subquora/query_embeddings.pkl\",\n",
    "            **kwargs):\n",
    "        #model is class should do nothing\n",
    "        self.model = model\n",
    "        self.path_corpus_embeddings = path_corpus_embeddings\n",
    "        self.path_query_embeddings = path_query_embeddings\n",
    "        self.show_progress_bar = kwargs.get(\"show_progress_bar\", True)\n",
    "        self.convert_to_tensor = kwargs.get(\"convert_to_tensor\", True)\n",
    "        self.results = {}\n",
    "\n",
    "        logger.info(\"Load in Encoded Queries and Corpus from Pickle...\")\n",
    "        # Verify file existence\n",
    "        if not os.path.exists(self.path_corpus_embeddings):\n",
    "            raise FileNotFoundError(f\"File '{self.path_corpus_embeddings}' not found.\")\n",
    "        if not os.path.exists(self.path_query_embeddings):\n",
    "            raise FileNotFoundError(f\"File '{self.path_query_embeddings}' not found.\")\n",
    "\n",
    "        with open(self.path_query_embeddings, \"rb\") as f:\n",
    "            self.query_embeddings = pickle.load(f)\n",
    "\n",
    "        with open(self.path_corpus_embeddings, \"rb\") as f:\n",
    "            self.corpus_embeddings = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "    def add_rounding(self, rounding_decimal: int) -> None:\n",
    "        # rounding decimal\n",
    "        if rounding_decimal < 12:\n",
    "            logger.info(\"Rounding decimal places of Queries and Corpus...\")\n",
    "            for key, value in self.query_embeddings.items():\n",
    "                self.query_embeddings[key] = np.round(value, decimals=rounding_decimal)\n",
    "\n",
    "            for key, value in self.corpus_embeddings.items():\n",
    "                self.corpus_embeddings[key] = np.round(value, decimals=rounding_decimal)\n",
    "\n",
    "    def add_noise(self, rounding_decimal: int) -> None:\n",
    "        logger.info(\"Adding Noise to Queries and Corpus...\")\n",
    "        for key, value in self.query_embeddings.items():\n",
    "            self.query_embeddings[key] += np.random.random() / 10**rounding_decimal\n",
    "\n",
    "        for key, value in self.corpus_embeddings.items():\n",
    "            self.corpus_embeddings[key] += np.random.random() / 10**rounding_decimal\n",
    "\n",
    "\n",
    "    def search(self,\n",
    "               corpus: Dict[str, Dict[str, str]],\n",
    "               queries: Dict[str, str],\n",
    "               top_k: int,\n",
    "               score_function: str,\n",
    "               return_sorted: bool = False,\n",
    "               **kwargs) -> Dict[str, Dict[str, float]]:\n",
    "        # Runs semantic search against the corpus embeddings\n",
    "        # Returns a ranked list with the corpus ids\n",
    "\n",
    "        query_ids = list(self.query_embeddings.keys())\n",
    "        self.results = {qid: {} for qid in query_ids}\n",
    "\n",
    "        # print(\"Sorting Corpus by document length (Longest first)...\")\n",
    "        logger.info(\"Sorting Corpus by document length (Longest first)...\")\n",
    "        corpus_ids = sorted(list(self.corpus_embeddings.keys()), reverse=True)\n",
    "\n",
    "        result_heaps = {qid: [] for qid in query_ids}  # Keep only the top-k docs for each query\n",
    "\n",
    "        # Convert dictionary values to PyTorch tensors\n",
    "        corpus_tensors = [torch.tensor(embedding) for embedding in self.corpus_embeddings.values()]\n",
    "        query_tensors = [torch.tensor(embedding) for embedding in self.query_embeddings.values()]\n",
    "        # Stack tensors along a new dimension (batch dimension)\n",
    "        corpus_embeddings_tensor = torch.stack(corpus_tensors)\n",
    "        query_embeddings_tensor = torch.stack(query_tensors)\n",
    "\n",
    "        # print(\"Compute similarites using  cosine-similarity\")\n",
    "        # Compute similarites using  cosine-similarity\n",
    "        cos_scores = cos_sim(query_embeddings_tensor, corpus_embeddings_tensor)\n",
    "        # print(\"cos_sim after\")\n",
    "        cos_scores[torch.isnan(cos_scores)] = -1\n",
    "\n",
    "        # print(\"Get top-k values\")\n",
    "        # Get top-k values\n",
    "        cos_scores_top_k_values, cos_scores_top_k_idx = torch.topk(cos_scores, min(top_k+1, len(cos_scores[1])), dim=1, largest=True, sorted=return_sorted)\n",
    "        cos_scores_top_k_values = cos_scores_top_k_values.cpu().tolist()\n",
    "        cos_scores_top_k_idx = cos_scores_top_k_idx.cpu().tolist()\n",
    "\n",
    "        # print(\"build heap\")\n",
    "        for query_itr in range(len(query_embeddings_tensor)):\n",
    "            query_id = query_ids[query_itr]\n",
    "            for sub_corpus_id, score in zip(cos_scores_top_k_idx[query_itr], cos_scores_top_k_values[query_itr]):\n",
    "                corpus_id = corpus_ids[sub_corpus_id]\n",
    "                if corpus_id != query_id:\n",
    "                    if len(result_heaps[query_id]) < top_k:\n",
    "                        # Push item on the heap\n",
    "                        heapq.heappush(result_heaps[query_id], (score, corpus_id))\n",
    "                    else:\n",
    "                        # If item is larger than the smallest in the heap, push it on the heap then pop the smallest element\n",
    "                        heapq.heappushpop(result_heaps[query_id], (score, corpus_id))\n",
    "\n",
    "        print(\"get results heaps\")\n",
    "        for qid in result_heaps:\n",
    "            for score, corpus_id in result_heaps[qid]:\n",
    "                self.results[qid][corpus_id] = score\n",
    "\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03341484069824219,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "model.safetensors",
       "rate": null,
       "total": 265462608,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5047e594dc874212807b491d60f38271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beir_sbert = NewSentenceBERT(sbert_model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "12 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 12 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00051} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00021, 'Recall@1000': 0.00402} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "11 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 11 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00051} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00021, 'Recall@1000': 0.00402} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "10 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 10 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00051} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00021, 'Recall@1000': 0.00402} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "9 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 9 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00051} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00021, 'Recall@1000': 0.00402} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "8 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 8 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00051} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00021, 'Recall@1000': 0.00402} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "7 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 7 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00051} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00021, 'Recall@1000': 0.00402} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "6 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 6 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00051} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00021, 'Recall@1000': 0.00402} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "5 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 5 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00051} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00021, 'Recall@1000': 0.00402} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "4 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 4 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00051} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00021, 'Recall@1000': 0.00402} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "3 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 3 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00051} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00021, 'Recall@1000': 0.00402} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "2 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 2 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00051} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00021, 'Recall@1000': 0.00402} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "1 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 1 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00053} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00021, 'Recall@1000': 0.00422} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "0 <class 'int'>\n",
      "after add_rounding\n",
      "after EvaluateRetrieval\n",
      "get results heaps\n",
      "after retrieve\n",
      "decimal_places: 0 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 1e-05, 'NDCG@1000': 0.0005} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 0.0, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 4e-05, 'Recall@1000': 0.00364} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "model = ExperiementRetrievalExactSearch(\n",
    "    beir_sbert,\n",
    "    path_corpus_embeddings = \"datasets/subquora/corpus_embeddings_half2.pkl\",\n",
    "    path_query_embeddings= \"datasets/subquora/query_embeddings_half2.pkl\") # This can go outside the loop\n",
    "\n",
    "print(\"here\")\n",
    "with open(\"datasets/subquora/qrels_half2.json\", \"r\") as f:\n",
    "    qrels = json.load(f)\n",
    "\n",
    "with open(\"datasets/subquora/query_embeddings_half2.pkl\", \"rb\") as f:\n",
    "    query_embeddings = pickle.load(f)\n",
    "\n",
    "with open(\"datasets/subquora/corpus_embeddings_half2.pkl\", \"rb\") as f:\n",
    "    corpus_embeddings = pickle.load(f)\n",
    "\n",
    "\n",
    "rounding_recalls = []\n",
    "rounding_decimals = range(12,-1,-1)\n",
    "for decimal in rounding_decimals:\n",
    "    print(decimal, type(decimal))\n",
    "    model.add_rounding(decimal)\n",
    "    print(\"after add_rounding\")\n",
    "    retriever = EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "    print(\"after EvaluateRetrieval\")\n",
    "    # print(model.corpus_embeddings, model.query_embeddings)\n",
    "    # issue maybe you have to pass the correct corpus and queries in\n",
    "    results = retriever.retrieve(corpus_embeddings, query_embeddings)\n",
    "    print(\"after retrieve\")\n",
    "    ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "    print(\"decimal_places:\", decimal , ndcg, _map, recall, precision )\n",
    "    #recall@100 matters mostr, save to array for plotting\n",
    "    rounding_recalls.append(recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get results heaps\n",
      "noise decimal: 12 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 1e-05, 'NDCG@1000': 0.0005} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 0.0, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 4e-05, 'Recall@1000': 0.00364} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "get results heaps\n",
      "noise decimal: 11 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 1e-05, 'NDCG@1000': 0.0005} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 0.0, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 4e-05, 'Recall@1000': 0.00364} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "get results heaps\n",
      "noise decimal: 10 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 1e-05, 'NDCG@1000': 0.0005} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 0.0, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 4e-05, 'Recall@1000': 0.00364} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "get results heaps\n",
      "noise decimal: 9 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 1e-05, 'NDCG@1000': 0.0005} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 0.0, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 4e-05, 'Recall@1000': 0.00364} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "get results heaps\n",
      "noise decimal: 8 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 1e-05, 'NDCG@1000': 0.0005} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 0.0, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 4e-05, 'Recall@1000': 0.00364} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "get results heaps\n",
      "noise decimal: 7 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 1e-05, 'NDCG@1000': 0.00055} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 0.0, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 4e-05, 'Recall@1000': 0.00409} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "get results heaps\n",
      "noise decimal: 6 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 3e-05, 'NDCG@1000': 0.00057} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 0.0, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00011, 'Recall@1000': 0.0043} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "get results heaps\n",
      "noise decimal: 5 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 4e-05, 'NDCG@1000': 0.00057} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 0.0, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00024, 'Recall@1000': 0.00425} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "get results heaps\n",
      "noise decimal: 4 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 9e-05, 'NDCG@1000': 0.00057} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 1e-05, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00051, 'Recall@1000': 0.00424} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 1e-05, 'P@1000': 1e-05}\n",
      "get results heaps\n",
      "noise decimal: 3 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00053} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 0.0, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00027, 'Recall@1000': 0.00389} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 1e-05, 'P@1000': 1e-05}\n",
      "get results heaps\n",
      "noise decimal: 2 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 1e-05, 'NDCG@1000': 0.00053} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 0.0, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 4e-05, 'Recall@1000': 0.00389} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 0.0, 'P@1000': 1e-05}\n",
      "get results heaps\n",
      "noise decimal: 1 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 0.0, 'NDCG@100': 5e-05, 'NDCG@1000': 0.00045} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 0.0, 'MAP@100': 0.0, 'MAP@1000': 1e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@100': 0.00019, 'Recall@1000': 0.00323} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 0.0, 'P@100': 1e-05, 'P@1000': 1e-05}\n",
      "get results heaps\n",
      "noise decimal: 0 {'NDCG@1': 0.0, 'NDCG@3': 0.0, 'NDCG@5': 0.0, 'NDCG@10': 2e-05, 'NDCG@100': 8e-05, 'NDCG@1000': 0.00055} {'MAP@1': 0.0, 'MAP@3': 0.0, 'MAP@5': 0.0, 'MAP@10': 1e-05, 'MAP@100': 1e-05, 'MAP@1000': 2e-05} {'Recall@1': 0.0, 'Recall@3': 0.0, 'Recall@5': 0.0, 'Recall@10': 4e-05, 'Recall@100': 0.00031, 'Recall@1000': 0.00408} {'P@1': 0.0, 'P@3': 0.0, 'P@5': 0.0, 'P@10': 2e-05, 'P@100': 1e-05, 'P@1000': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "noise_recalls = []\n",
    "noise_decimals = range(12,-1,-1)\n",
    "for decimal in range(12,-1,-1):\n",
    "    # print(decimal, type(decimal))\n",
    "    model.add_noise(decimal)\n",
    "    # model.noise()\n",
    "    retriever = EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "    results = retriever.retrieve(model.corpus_embeddings, model.query_embeddings)\n",
    "    ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "    print(\"noise decimal:\", decimal , ndcg, _map, recall, precision )\n",
    "    noise_recalls.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Headers for CSV file\n",
    "headers = ['Rounding_Decimals', 'Recall@100', 'Recall@1000']\n",
    "\n",
    "# Create and write data to CSV file\n",
    "with open('results/rounding_recalls_half.csv', 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for rounding_decimal, rounding_recall in zip(rounding_decimals, rounding_recalls):\n",
    "        row_data = {\n",
    "            'Rounding_Decimals': rounding_decimal,\n",
    "            'Recall@100': rounding_recall['Recall@100'],\n",
    "            'Recall@1000': rounding_recall['Recall@1000']\n",
    "        }\n",
    "        writer.writerow(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers for CSV file\n",
    "headers = ['Rounding_Decimals', 'Recall@100', 'Recall@1000']\n",
    "\n",
    "# Create and write data to CSV file\n",
    "with open('results/noise_recall_half.csv', 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for rounding_decimal, noise_recall in zip(rounding_decimals, noise_recalls):\n",
    "        row_data = {\n",
    "            'Rounding_Decimals': rounding_decimal,\n",
    "            'Recall@100': noise_recall['Recall@100'],\n",
    "            'Recall@1000': noise_recall['Recall@1000']\n",
    "        }\n",
    "        writer.writerow(row_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
