{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is going to use BEIR to download a dataset and create embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. embeddings, saving & loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "DATASET = \"scifact\"\n",
    "sbert_model_name = \"msmarco-distilbert-base-tas-b\"\n",
    "device = \"cpu\" # cuda for gpu usage\n",
    "#  using full dataset\n",
    "# k_queries = 10000\n",
    "# k_documents = 522931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/tsouth/.local/lib/python3.10/site-packages/beir/util.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2024-05-13 14:52:39.345256: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-13 14:52:39.345403: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-13 14:52:39.345469: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-13 14:52:39.367735: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 14:52:50.591802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from time import time\n",
    "from beir import util\n",
    "from beir_reengineered import NewSentenceBERT\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "import os, json, random\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Download nfcorpus.zip dataset and unzip the dataset\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(DATASET)\n",
    "out_dir = \"datasets\"\n",
    "data_path = util.download_and_unzip(url, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0725557804107666,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5183,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1ac858b3de49399ea6705b2a813e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Provide the data path where nfcorpus has been downloaded and unzipped to the data loader\n",
    "# data folder would contain these files:\n",
    "# (1) nfcorpus/corpus.jsonl  (format: jsonlines)\n",
    "# (2) nfcorpus/queries.jsonl (format: jsonlines)\n",
    "# (3) nfcorpus/qrels/test.tsv (format: tsv (\"\\t\"))\n",
    "\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8841823 43\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus), len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dense Retrieval using SBERT (Sentence-BERT) ####\n",
    "#### Provide any pretrained sentence-transformers model\n",
    "#### The model was fine-tuned using cosine-similarity.\n",
    "#### Complete list - https://www.sbert.net/docs/pretrained_models.html\n",
    "\n",
    "beir_sbert = NewSentenceBERT(sbert_model_name, device=device)\n",
    "model = DRES(beir_sbert, batch_size=256, corpus_chunk_size=512*9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create sub-sample\n",
    "# subset_of_queries = random.sample(queries.keys(), k_queries)\n",
    "# queries = {qid: queries[qid] for qid in subset_of_queries}\n",
    "# qrels = {qid: qrels[qid] for qid in subset_of_queries}\n",
    "# true_documents = set([docid for qid in qrels for docid in qrels[qid]])\n",
    "# false_documents = set(random.sample(list(set([docid for docid in corpus if docid not in true_documents])), k_documents))\n",
    "# subset_of_corpus = true_documents | false_documents\n",
    "# corpus = {docid: corpus[docid] for docid in subset_of_corpus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'31715818': 1},\n",
       " '3': {'14717500': 1},\n",
       " '5': {'13734012': 1},\n",
       " '13': {'1606628': 1},\n",
       " '36': {'5152028': 1, '11705328': 1},\n",
       " '42': {'18174210': 1},\n",
       " '48': {'13734012': 1},\n",
       " '49': {'5953485': 1},\n",
       " '50': {'12580014': 1},\n",
       " '51': {'45638119': 1},\n",
       " '53': {'45638119': 1},\n",
       " '54': {'49556906': 1},\n",
       " '56': {'4709641': 1},\n",
       " '57': {'4709641': 1},\n",
       " '70': {'5956380': 1, '4414547': 1},\n",
       " '72': {'6076903': 1},\n",
       " '75': {'4387784': 1},\n",
       " '94': {'1215116': 1},\n",
       " '99': {'18810195': 1},\n",
       " '100': {'4381486': 1},\n",
       " '113': {'6157837': 1},\n",
       " '115': {'33872649': 1},\n",
       " '118': {'6372244': 1},\n",
       " '124': {'4883040': 1},\n",
       " '127': {'21598000': 1},\n",
       " '128': {'8290953': 1},\n",
       " '129': {'27768226': 1},\n",
       " '130': {'27768226': 1},\n",
       " '132': {'7975937': 1},\n",
       " '133': {'38485364': 1,\n",
       "  '6969753': 1,\n",
       "  '17934082': 1,\n",
       "  '16280642': 1,\n",
       "  '12640810': 1},\n",
       " '137': {'26016929': 1},\n",
       " '141': {'6955746': 1, '14437255': 1},\n",
       " '142': {'10582939': 1},\n",
       " '143': {'10582939': 1},\n",
       " '146': {'10582939': 1},\n",
       " '148': {'1084345': 1},\n",
       " '163': {'18872233': 1},\n",
       " '171': {'12670680': 1},\n",
       " '179': {'16322674': 1, '27123743': 1, '23557241': 1, '17450673': 1},\n",
       " '180': {'16966326': 1},\n",
       " '183': {'12827098': 1},\n",
       " '185': {'18340282': 1},\n",
       " '198': {'2177022': 1},\n",
       " '208': {'13519661': 1},\n",
       " '212': {'22038539': 1},\n",
       " '213': {'13625993': 1},\n",
       " '216': {'21366394': 1},\n",
       " '217': {'21366394': 1},\n",
       " '218': {'21366394': 1},\n",
       " '219': {'21366394': 1},\n",
       " '230': {'3067015': 1},\n",
       " '232': {'10536636': 1},\n",
       " '233': {'4388470': 1},\n",
       " '236': {'4388470': 1},\n",
       " '237': {'4942718': 1},\n",
       " '238': {'2251426': 1},\n",
       " '239': {'14079881': 1},\n",
       " '248': {'1568684': 1},\n",
       " '249': {'1568684': 1},\n",
       " '261': {'1122279': 1, '10697096': 1},\n",
       " '268': {'970012': 1},\n",
       " '269': {'970012': 1},\n",
       " '274': {'11614737': 1},\n",
       " '275': {'4961038': 1, '14241418': 1, '14819804': 1},\n",
       " '279': {'14376683': 1},\n",
       " '294': {'10874408': 1},\n",
       " '295': {'20310709': 1},\n",
       " '298': {'39381118': 1},\n",
       " '300': {'3553087': 1},\n",
       " '303': {'4388470': 1},\n",
       " '312': {'6173523': 1},\n",
       " '314': {'4347374': 1},\n",
       " '324': {'2014909': 1},\n",
       " '327': {'17997584': 1},\n",
       " '338': {'23349986': 1},\n",
       " '343': {'7873737': 1, '5884524': 1},\n",
       " '350': {'16927286': 1},\n",
       " '354': {'8774475': 1},\n",
       " '362': {'38587347': 1},\n",
       " '380': {'19005293': 1},\n",
       " '384': {'13770184': 1},\n",
       " '385': {'9955779': 1, '9767444': 1},\n",
       " '386': {'16495649': 1},\n",
       " '388': {'1148122': 1},\n",
       " '399': {'791050': 1},\n",
       " '410': {'14924526': 1},\n",
       " '411': {'14924526': 1},\n",
       " '415': {'6309659': 1},\n",
       " '421': {'11172205': 1},\n",
       " '431': {'28937856': 1},\n",
       " '436': {'14637235': 1},\n",
       " '437': {'18399038': 1},\n",
       " '439': {'4423559': 1},\n",
       " '440': {'4423559': 1},\n",
       " '443': {'10165258': 1},\n",
       " '452': {'12804937': 1, '464511': 1},\n",
       " '475': {'18678095': 1},\n",
       " '478': {'14767844': 1},\n",
       " '491': {'56893404': 1},\n",
       " '501': {'17930286': 1},\n",
       " '502': {'13071728': 1},\n",
       " '507': {'30774694': 1},\n",
       " '508': {'13980338': 1},\n",
       " '513': {'13230773': 1},\n",
       " '514': {'16256507': 1},\n",
       " '516': {'29564505': 1},\n",
       " '517': {'15663829': 1},\n",
       " '521': {'34873974': 1},\n",
       " '525': {'13639330': 1},\n",
       " '527': {'3863543': 1},\n",
       " '528': {'5476778': 1},\n",
       " '532': {'12991445': 1},\n",
       " '533': {'12991445': 1},\n",
       " '535': {'39368721': 1},\n",
       " '536': {'16056514': 1},\n",
       " '539': {'13282296': 1},\n",
       " '540': {'11886686': 1, '25007443': 1},\n",
       " '544': {'24221369': 1},\n",
       " '549': {'9433958': 1},\n",
       " '551': {'33499189': 1},\n",
       " '552': {'1471041': 1},\n",
       " '554': {'1049501': 1},\n",
       " '560': {'40096222': 1},\n",
       " '569': {'23460562': 1},\n",
       " '575': {'10300888': 1},\n",
       " '577': {'5289038': 1},\n",
       " '578': {'8764879': 1},\n",
       " '587': {'16999023': 1},\n",
       " '589': {'10984005': 1},\n",
       " '593': {'19675911': 1},\n",
       " '597': {'12779444': 1, '36355784': 1, '25742130': 1},\n",
       " '598': {'25742130': 1},\n",
       " '613': {'9638032': 1},\n",
       " '619': {'20888849': 1, '2565138': 1},\n",
       " '623': {'17000834': 1},\n",
       " '628': {'24512064': 1},\n",
       " '636': {'24294572': 1},\n",
       " '637': {'25649714': 1},\n",
       " '641': {'5912283': 1, '31554917': 1},\n",
       " '644': {'13619127': 1},\n",
       " '649': {'12789595': 1},\n",
       " '659': {'1215116': 1},\n",
       " '660': {'1215116': 1},\n",
       " '674': {'2095573': 1},\n",
       " '684': {'4942718': 1},\n",
       " '690': {'18750453': 1},\n",
       " '691': {'10991183': 1},\n",
       " '692': {'24088502': 1},\n",
       " '693': {'24088502': 1},\n",
       " '700': {'4350400': 1},\n",
       " '702': {'4350400': 1},\n",
       " '715': {'18421962': 1},\n",
       " '716': {'18421962': 1},\n",
       " '718': {'17587795': 1},\n",
       " '721': {'1834762': 1},\n",
       " '723': {'5531479': 1},\n",
       " '727': {'7521113': 1},\n",
       " '728': {'7521113': 1, '36444198': 1},\n",
       " '729': {'26851674': 1},\n",
       " '742': {'32159283': 1},\n",
       " '743': {'32159283': 1},\n",
       " '744': {'8460275': 1},\n",
       " '756': {'2831620': 1},\n",
       " '759': {'1805641': 1},\n",
       " '768': {'6421792': 1},\n",
       " '770': {'15476777': 1},\n",
       " '775': {'32275758': 1},\n",
       " '781': {'24338780': 1},\n",
       " '783': {'40632104': 1},\n",
       " '784': {'2356950': 1},\n",
       " '785': {'12471115': 1},\n",
       " '793': {'8551160': 1},\n",
       " '800': {'22543403': 1},\n",
       " '805': {'22180793': 1},\n",
       " '808': {'36606083': 1},\n",
       " '811': {'19799455': 1},\n",
       " '814': {'33387953': 1},\n",
       " '820': {'8646760': 1},\n",
       " '821': {'8646760': 1},\n",
       " '823': {'15319019': 1},\n",
       " '830': {'1897324': 1},\n",
       " '831': {'1897324': 1},\n",
       " '832': {'30303335': 1},\n",
       " '834': {'5483793': 1},\n",
       " '837': {'15928989': 1},\n",
       " '839': {'1469751': 1},\n",
       " '845': {'17741440': 1},\n",
       " '847': {'16787954': 1},\n",
       " '852': {'13843341': 1},\n",
       " '859': {'1982286': 1},\n",
       " '870': {'195689316': 1},\n",
       " '873': {'1180972': 1,\n",
       "  '19307912': 1,\n",
       "  '27393799': 1,\n",
       "  '29025270': 1,\n",
       "  '3315558': 1},\n",
       " '879': {'8426046': 1},\n",
       " '880': {'8426046': 1},\n",
       " '882': {'14803797': 1},\n",
       " '887': {'18855191': 1},\n",
       " '903': {'10648422': 1},\n",
       " '904': {'7370282': 1},\n",
       " '907': {'6923961': 1},\n",
       " '911': {'11254556': 1},\n",
       " '913': {'3203590': 1},\n",
       " '914': {'3203590': 1},\n",
       " '921': {'1642727': 1},\n",
       " '922': {'17077004': 1},\n",
       " '936': {'5483793': 1},\n",
       " '956': {'12956194': 1},\n",
       " '957': {'123859': 1},\n",
       " '960': {'8780599': 1},\n",
       " '967': {'2119889': 1, '8997410': 1},\n",
       " '971': {'46695481': 1, '27873158': 1, '28617573': 1, '9764256': 1},\n",
       " '975': {'5304891': 1},\n",
       " '982': {'2988714': 1},\n",
       " '985': {'6828370': 1},\n",
       " '993': {'16472469': 1},\n",
       " '1012': {'9745001': 1},\n",
       " '1014': {'6277638': 1},\n",
       " '1019': {'11603066': 1},\n",
       " '1020': {'9433958': 1},\n",
       " '1021': {'9433958': 1},\n",
       " '1024': {'5373138': 1},\n",
       " '1029': {'13923140': 1, '13940200': 1, '11899391': 1},\n",
       " '1041': {'25254425': 1, '16626264': 1},\n",
       " '1049': {'12486491': 1},\n",
       " '1062': {'20381484': 1},\n",
       " '1086': {'39281140': 1},\n",
       " '1088': {'37549932': 1},\n",
       " '1089': {'17628888': 1},\n",
       " '1099': {'7662206': 1},\n",
       " '1100': {'7662206': 1},\n",
       " '1104': {'3898784': 1},\n",
       " '1107': {'20532591': 1},\n",
       " '1110': {'13770184': 1},\n",
       " '1121': {'4456756': 1},\n",
       " '1130': {'17997584': 1},\n",
       " '1132': {'33499189': 1, '9283422': 1},\n",
       " '1137': {'33370': 1},\n",
       " '1140': {'12009265': 1},\n",
       " '1144': {'10071552': 1},\n",
       " '1146': {'13906581': 1},\n",
       " '1150': {'11369420': 1},\n",
       " '1163': {'15305881': 1},\n",
       " '1175': {'31272411': 1},\n",
       " '1179': {'31272411': 1},\n",
       " '1180': {'31272411': 1},\n",
       " '1185': {'16737210': 1},\n",
       " '1187': {'52873726': 1},\n",
       " '1191': {'30655442': 1},\n",
       " '1194': {'11419230': 1},\n",
       " '1196': {'25649714': 1},\n",
       " '1197': {'25649714': 1},\n",
       " '1199': {'16760369': 1},\n",
       " '1200': {'3441524': 1},\n",
       " '1202': {'3475317': 1},\n",
       " '1204': {'31141365': 1},\n",
       " '1207': {'18909530': 1},\n",
       " '1213': {'14407673': 1},\n",
       " '1216': {'24142891': 1},\n",
       " '1221': {'19736671': 1},\n",
       " '1225': {'9650982': 1},\n",
       " '1226': {'13777138': 1},\n",
       " '1232': {'13905670': 1},\n",
       " '1241': {'4427392': 1},\n",
       " '1245': {'7662395': 1},\n",
       " '1259': {'24341590': 1},\n",
       " '1262': {'44172171': 1},\n",
       " '1266': {'37480103': 1},\n",
       " '1270': {'13900610': 1},\n",
       " '1271': {'13768432': 1},\n",
       " '1272': {'17081238': 1},\n",
       " '1273': {'11041152': 1},\n",
       " '1274': {'12428814': 1, '27731651': 1, '4406819': 1},\n",
       " '1278': {'11335781': 1},\n",
       " '1279': {'11335781': 1},\n",
       " '1280': {'4387784': 1},\n",
       " '1281': {'4387784': 1},\n",
       " '1282': {'23649163': 1},\n",
       " '1290': {'4687948': 1},\n",
       " '1292': {'56893404': 1},\n",
       " '1298': {'11718220': 1},\n",
       " '1303': {'12631697': 1},\n",
       " '1316': {'27910499': 1},\n",
       " '1319': {'16284655': 1},\n",
       " '1320': {'16284655': 1},\n",
       " '1332': {'5304891': 1},\n",
       " '1335': {'27910499': 1},\n",
       " '1336': {'27910499': 1},\n",
       " '1337': {'20231138': 1},\n",
       " '1339': {'15482274': 1},\n",
       " '1344': {'9559146': 1},\n",
       " '1352': {'12885341': 1},\n",
       " '1359': {'11614737': 1},\n",
       " '1362': {'8290953': 1},\n",
       " '1363': {'8290953': 1},\n",
       " '1368': {'2425364': 1},\n",
       " '1370': {'2425364': 1},\n",
       " '1379': {'16322674': 1, '27123743': 1, '23557241': 1, '17450673': 1},\n",
       " '1382': {'17755060': 1},\n",
       " '1385': {'306006': 1},\n",
       " '1389': {'23895668': 1},\n",
       " '1395': {'17717391': 1}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save qrels to a JSON file\n",
    "with open(\"datasets/{DATASET}/qrels_full.json\", \"w\") as f:\n",
    "    json.dump(qrels, f)\n",
    "\n",
    "# with open(\"datasets/scifact/qrels_half_new.json\", \"r\") as f:\n",
    "#     qrels_json = json.load(f)\n",
    "# qrels_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.04124903678894043,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Batches",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6622b62c454b420dbc5fd6e7e1e58420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode queries\n",
    "queries_l = [queries[qid] for qid in queries]\n",
    "query_embeddings = model.model.encode_queries(\n",
    "    queries_l,\n",
    "    batch_size=model.batch_size,\n",
    "    show_progress_bar=model.show_progress_bar,\n",
    "    convert_to_tensor=model.convert_to_tensor\n",
    ").cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.06003260612487793,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Batches",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f7cef7cb62432cb4197408afbaea5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queries_l = [queries[qid] for qid in queries]\n",
    "query_embeddings_no_numpy = model.model.encode_queries(\n",
    "    queries_l,\n",
    "    batch_size=model.batch_size,\n",
    "    show_progress_bar=model.show_progress_bar,\n",
    "    convert_to_tensor=model.convert_to_tensor\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.3457e-02, -6.4940e-02,  1.1919e-01,  ...,  2.1156e-01,\n",
      "         -1.2849e-01,  2.5972e-01],\n",
      "        [-4.8527e-02, -1.0737e-02, -2.7499e-01,  ..., -3.9596e-01,\n",
      "         -1.1906e-01,  3.8540e-03],\n",
      "        [-2.1471e-01, -1.1597e-01,  1.7311e-01,  ..., -1.3831e-01,\n",
      "          5.4625e-03,  3.3365e-01],\n",
      "        ...,\n",
      "        [-2.2542e-01,  1.7411e-01,  3.1678e-01,  ..., -2.7437e-01,\n",
      "         -1.8800e-01,  1.3263e-02],\n",
      "        [-8.6582e-02,  2.4527e-01,  2.8209e-01,  ...,  2.1545e-01,\n",
      "         -1.6390e-01,  3.7964e-01],\n",
      "        [-9.9246e-02,  3.8544e-01,  5.2913e-01,  ...,  1.8654e-01,\n",
      "         -4.2470e-01,  2.8622e-04]]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(query_embeddings_no_numpy, type(query_embeddings_no_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "query_ids = list(query_embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.3456584e-02 -6.4939752e-02  1.1918864e-01 ...  2.1155570e-01\n",
      "  -1.2849271e-01  2.5971875e-01]\n",
      " [-4.8527356e-02 -1.0737373e-02 -2.7498850e-01 ... -3.9595616e-01\n",
      "  -1.1905648e-01  3.8539961e-03]\n",
      " [-2.1471177e-01 -1.1597147e-01  1.7310809e-01 ... -1.3830937e-01\n",
      "   5.4624751e-03  3.3364895e-01]\n",
      " ...\n",
      " [-2.2541705e-01  1.7411244e-01  3.1678286e-01 ... -2.7436656e-01\n",
      "  -1.8800369e-01  1.3262800e-02]\n",
      " [-8.6581841e-02  2.4526857e-01  2.8209364e-01 ...  2.1544777e-01\n",
      "  -1.6389754e-01  3.7963599e-01]\n",
      " [-9.9245831e-02  3.8543788e-01  5.2913320e-01 ...  1.8653692e-01\n",
      "  -4.2469692e-01  2.8622171e-04]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(query_embeddings, type(query_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 1.9162752628326416,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Batches",
       "rate": null,
       "total": 34539,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183f6c8eb49047f8a31dd0d685366a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/34539 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode documents\n",
    "corpus_ids = sorted(corpus, key=lambda k: len(corpus[k].get(\"title\", \"\") + corpus[k].get(\"text\", \"\")), reverse=True)\n",
    "corpus_l = [corpus[cid] for cid in corpus_ids]\n",
    "sub_corpus_embeddings = model.model.encode_corpus(\n",
    "    corpus_l,\n",
    "    batch_size=model.batch_size,\n",
    "    show_progress_bar=model.show_progress_bar,\n",
    "    convert_to_tensor=model.convert_to_tensor\n",
    ").cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as new dataset\n",
    "os.makedirs(\"datasets/msmarco/qrels\", exist_ok=True)\n",
    "with open(\"datasets/msmarco/queries.jsonl\", \"w\") as f:\n",
    "    f.writelines([json.dumps({\"_id\": qid, \"text\": queries[qid], \"metadata\":{}})+\"\\n\" for qid in queries])\n",
    "with open(\"datasets/msmarco/corpus.jsonl\", \"w\") as f:\n",
    "    f.writelines([json.dumps({\"_id\": docid, \"title\": corpus[docid].get(\"title\"), \"text\": corpus[docid].get(\"text\"), \"metadata\":{}})+\"\\n\" for docid in corpus])\n",
    "with open(\"datasets/msmarco/qrels/test.tsv\", \"w\") as f:\n",
    "    f.write(\"query-id\\tcorpus-id\\tscore\\n\")\n",
    "    for qid in qrels:\n",
    "        for docid in qrels[qid]:\n",
    "            f.write(\"{}\\t{}\\t{}\\n\".format(qid, docid, qrels[qid][docid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save embeddings\n",
    "corpus_embeddings_dict = dict(zip(corpus_ids, sub_corpus_embeddings))\n",
    "query_embeddings_dict = dict(zip(queries.keys(), query_embeddings))\n",
    "import pickle\n",
    "\n",
    "with open(\"datasets/msmarco/corpus_embeddings_full.pkl\", \"wb\") as f:\n",
    "    pickle.dump(corpus_embeddings_dict, f)\n",
    "with open(\"datasets/msmarco/query_embeddings_full.pkl\", \"wb\") as f:\n",
    "    pickle.dump(query_embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10th of data\n",
    "k_queries = 1000\n",
    "k_documents = 52293\n",
    "\n",
    "quater of data\n",
    "k_queries = 2500\n",
    "k_documents = 130732\n",
    "\n",
    "half of data \n",
    "k_queries = 5000\n",
    "k_documents = 261465"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. (only sometimes) round embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/tsouth/.local/lib/python3.10/site-packages/beir/util.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from beir.retrieval.search import BaseSearch # type: ignore beir/retrieval/search/dense/exact_search.py\n",
    "from beir.util import cos_sim\n",
    "import torch # type: ignore\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import heapq\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: refactor to have base class with rounding and noise\n",
    "\n",
    "# ExperiementRetrievalExactSearch is parent class for any model we are using for our experiement that can be used for retrieval\n",
    "# Abstract class is BaseSearch\n",
    "class ExperiementRetrievalExactSearch(BaseSearch):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            path_corpus_embeddings: str,\n",
    "            path_query_embeddings: str,\n",
    "            **kwargs):\n",
    "        #model is class should do nothing\n",
    "        self.model = model\n",
    "        self.path_corpus_embeddings = path_corpus_embeddings\n",
    "        self.path_query_embeddings = path_query_embeddings\n",
    "        self.show_progress_bar = kwargs.get(\"show_progress_bar\", True)\n",
    "        self.convert_to_tensor = kwargs.get(\"convert_to_tensor\", True)\n",
    "        self.results = {}\n",
    "\n",
    "        logger.info(\"Load in Encoded Queries and Corpus from Pickle...\")\n",
    "        # Verify file existence\n",
    "        if not os.path.exists(self.path_corpus_embeddings):\n",
    "            raise FileNotFoundError(f\"File '{self.path_corpus_embeddings}' not found.\")\n",
    "        if not os.path.exists(self.path_query_embeddings):\n",
    "            raise FileNotFoundError(f\"File '{self.path_query_embeddings}' not found.\")\n",
    "\n",
    "        with open(self.path_query_embeddings, \"rb\") as f:\n",
    "            self.query_embeddings = pickle.load(f)\n",
    "\n",
    "        with open(self.path_corpus_embeddings, \"rb\") as f:\n",
    "            self.corpus_embeddings = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "    def add_rounding(self, rounding_decimal: int) -> None:\n",
    "        # rounding decimal\n",
    "        if rounding_decimal < 12:\n",
    "            logger.info(\"Rounding decimal places of Queries and Corpus...\")\n",
    "            for key, value in self.query_embeddings.items():\n",
    "                self.query_embeddings[key] = np.round(value, decimals=rounding_decimal)\n",
    "\n",
    "            for key, value in self.corpus_embeddings.items():\n",
    "                self.corpus_embeddings[key] = np.round(value, decimals=rounding_decimal)\n",
    "\n",
    "    def add_noise(self, rounding_decimal: int) -> None:\n",
    "        logger.info(\"Adding Noise to Queries and Corpus...\")\n",
    "        for key, value in self.query_embeddings.items():\n",
    "            self.query_embeddings[key] += np.random.random() / 10**rounding_decimal\n",
    "\n",
    "        for key, value in self.corpus_embeddings.items():\n",
    "            self.corpus_embeddings[key] += np.random.random() / 10**rounding_decimal\n",
    "\n",
    "\n",
    "    def search(self,\n",
    "               corpus: Dict[str, Dict[str, str]],\n",
    "               queries: Dict[str, str],\n",
    "               top_k: int,\n",
    "               score_function: str,\n",
    "               return_sorted: bool = False,\n",
    "               **kwargs) -> Dict[str, Dict[str, float]]:\n",
    "        # Runs semantic search against the corpus embeddings\n",
    "        # Returns a ranked list with the corpus ids\n",
    "\n",
    "        query_ids = list(self.query_embeddings.keys())\n",
    "        self.results = {qid: {} for qid in query_ids}\n",
    "\n",
    "        # print(\"Sorting Corpus by document length (Longest first)...\")\n",
    "        logger.info(\"Sorting Corpus by document length (Longest first)...\")\n",
    "        corpus_ids = sorted(list(self.corpus_embeddings.keys()), reverse=True)\n",
    "\n",
    "        result_heaps = {qid: [] for qid in query_ids}  # Keep only the top-k docs for each query\n",
    "\n",
    "        # Convert dictionary values to PyTorch tensors\n",
    "        corpus_tensors = [torch.tensor(embedding) for embedding in self.corpus_embeddings.values()]\n",
    "        query_tensors = [torch.tensor(embedding) for embedding in self.query_embeddings.values()]\n",
    "        # Stack tensors along a new dimension (batch dimension)\n",
    "        corpus_embeddings_tensor = torch.stack(corpus_tensors)\n",
    "        query_embeddings_tensor = torch.stack(query_tensors)\n",
    "\n",
    "        # print(\"Compute similarites using  cosine-similarity\")\n",
    "        # Compute similarites using  cosine-similarity\n",
    "        cos_scores = cos_sim(query_embeddings_tensor, corpus_embeddings_tensor)\n",
    "        cos_scores[torch.isnan(cos_scores)] = -1\n",
    "\n",
    "        # print(\"Get top-k values\")\n",
    "        # Get top-k values\n",
    "        cos_scores_top_k_values, cos_scores_top_k_idx = torch.topk(cos_scores, min(top_k+1, len(cos_scores[1])), dim=1, largest=True, sorted=return_sorted)\n",
    "        cos_scores_top_k_values = cos_scores_top_k_values.cpu().tolist()\n",
    "        cos_scores_top_k_idx = cos_scores_top_k_idx.cpu().tolist()\n",
    "\n",
    "        # print(\"build heap\")\n",
    "        for query_itr in range(len(query_embeddings_tensor)):\n",
    "            query_id = query_ids[query_itr]\n",
    "            for sub_corpus_id, score in zip(cos_scores_top_k_idx[query_itr], cos_scores_top_k_values[query_itr]):\n",
    "                corpus_id = corpus_ids[sub_corpus_id]\n",
    "                if corpus_id != query_id:\n",
    "                    if len(result_heaps[query_id]) < top_k:\n",
    "                        # Push item on the heap\n",
    "                        heapq.heappush(result_heaps[query_id], (score, corpus_id))\n",
    "                    else:\n",
    "                        # If item is larger than the smallest in the heap, push it on the heap then pop the smallest element\n",
    "                        heapq.heappushpop(result_heaps[query_id], (score, corpus_id))\n",
    "\n",
    "        print(\"get results heaps\")\n",
    "        for qid in result_heaps:\n",
    "            for score, corpus_id in result_heaps[qid]:\n",
    "                self.results[qid][corpus_id] = score\n",
    "\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "print(\"here\")\n",
    "with open(\"datasets/msmarco/qrels_full.json\", \"r\") as f:\n",
    "    qrels = json.load(f)\n",
    "\n",
    "with open(\"datasets/msmarco/query_embeddings_full.pkl\", \"rb\") as f:\n",
    "    query_embeddings = pickle.load(f)\n",
    "\n",
    "with open(\"datasets/msmarco/corpus_embeddings_full.pkl\", \"rb\") as f:\n",
    "    corpus_embeddings = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beir_sbert = NewSentenceBERT(sbert_model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m ExperiementRetrievalExactSearch(\n\u001b[1;32m      3\u001b[0m     beir_sbert,\n\u001b[1;32m      4\u001b[0m     path_corpus_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/scifact/corpus_embeddings_full.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     path_query_embeddings\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/scifact/query_embeddings_full.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      6\u001b[0m retriever \u001b[38;5;241m=\u001b[39m EvaluateRetrieval(model, score_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos_sim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# or \"cos_sim\" for cosine similarity\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m retriever\u001b[38;5;241m.\u001b[39mretrieve(\u001b[43mcorpus\u001b[49m, queries)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "#### Load the SBERT model and retrieve using cosine-similarity\n",
    "model = ExperiementRetrievalExactSearch(\n",
    "    beir_sbert,\n",
    "    path_corpus_embeddings = \"datasets/msmarco/corpus_embeddings_full.pkl\",\n",
    "    path_query_embeddings= \"datasets/msmarco/query_embeddings_full.pkl\") #\n",
    "retriever = EvaluateRetrieval(model, score_function=\"cos_sim\") # or \"cos_sim\" for cosine similarity\n",
    "\n",
    "\n",
    "retriever = EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "print(\"after EvaluateRetrieval\")\n",
    "# print(model.corpus_embeddings, model.query_embeddings)\n",
    "# issue maybe you have to pass the correct corpus and queries in\n",
    "results = retriever.retrieve(corpus_embeddings, query_embeddings)\n",
    "print(\"after retrieve\")\n",
    "ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "print( ndcg, _map, recall, precision )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beir_sbert = NewSentenceBERT(sbert_model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_des = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Headers for CSV file\n",
    "headers = ['Rounding_Decimals', 'Recall@100', 'Recall@1000']\n",
    "\n",
    "# Create and write data to CSV file\n",
    "with open('results/msmarco/recall_full.csv', 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "\n",
    "    row_data = {\n",
    "        'Rounding_Decimals': 12,\n",
    "        'Recall@100': recall['Recall@100'],\n",
    "        'Recall@1000': recall['Recall@1000']\n",
    "    }\n",
    "    writer.writerow(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ExperiementRetrievalExactSearch(\n",
    "#     beir_sbert,\n",
    "#     path_corpus_embeddings = \"datasets/scifact/corpus_embeddings_full.pkl\",\n",
    "#     path_query_embeddings= \"datasets/scifact/query_embeddings_full.pkl\") # This can go outside the loop\n",
    "\n",
    "# print(\"here\")\n",
    "# with open(\"datasets/scifact/qrels_full.json\", \"r\") as f:\n",
    "#     qrels = json.load(f)\n",
    "\n",
    "# with open(\"datasets/scifact/query_embeddings_full.pkl\", \"rb\") as f:\n",
    "#     query_embeddings = pickle.load(f)\n",
    "\n",
    "# with open(\"datasets/scifact/corpus_embeddings_full.pkl\", \"rb\") as f:\n",
    "#     corpus_embeddings = pickle.load(f)\n",
    "\n",
    "\n",
    "# rounding_recalls = []\n",
    "# rounding_decimals = range(12,-1,-1)\n",
    "# for decimal in rounding_decimals:\n",
    "#     print(decimal, type(decimal))\n",
    "#     model.add_rounding(decimal)\n",
    "#     print(\"after add_rounding\")\n",
    "#     retriever = EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "#     print(\"after EvaluateRetrieval\")\n",
    "#     # print(model.corpus_embeddings, model.query_embeddings)\n",
    "#     # issue maybe you have to pass the correct corpus and queries in\n",
    "#     results = retriever.retrieve(corpus_embeddings, query_embeddings)\n",
    "#     print(\"after retrieve\")\n",
    "#     ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "#     print(\"decimal_places:\", decimal , ndcg, _map, recall, precision )\n",
    "#     #recall@100 matters mostr, save to array for plotting\n",
    "#     rounding_recalls.append(recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_recalls = []\n",
    "# noise_decimals = range(12,-1,-1)\n",
    "# for decimal in range(12,-1,-1):\n",
    "#     # print(decimal, type(decimal))\n",
    "#     model.add_noise(decimal)\n",
    "#     # model.noise()\n",
    "#     retriever = EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "#     results = retriever.retrieve(model.corpus_embeddings, model.query_embeddings)\n",
    "#     ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "#     print(\"noise decimal:\", decimal , ndcg, _map, recall, precision )\n",
    "#     noise_recalls.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# # Headers for CSV file\n",
    "# headers = ['Rounding_Decimals', 'Recall@100', 'Recall@1000']\n",
    "\n",
    "# # Create and write data to CSV file\n",
    "# with open('results/scifact/rounding_recalls_full.csv', 'w', newline='') as file:\n",
    "#     writer = csv.DictWriter(file, fieldnames=headers)\n",
    "#     writer.writeheader()\n",
    "\n",
    "#     for rounding_decimal, rounding_recall in zip(rounding_decimals, rounding_recalls):\n",
    "#         row_data = {\n",
    "#             'Rounding_Decimals': rounding_decimal,\n",
    "#             'Recall@100': rounding_recall['Recall@100'],\n",
    "#             'Recall@1000': rounding_recall['Recall@1000']\n",
    "#         }\n",
    "#         writer.writerow(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Headers for CSV file\n",
    "# headers = ['Rounding_Decimals', 'Recall@100', 'Recall@1000']\n",
    "\n",
    "# # Create and write data to CSV file\n",
    "# with open('results/scifact/noise_recall_full.csv', 'w', newline='') as file:\n",
    "#     writer = csv.DictWriter(file, fieldnames=headers)\n",
    "#     writer.writeheader()\n",
    "\n",
    "#     for rounding_decimal, noise_recall in zip(rounding_decimals, noise_recalls):\n",
    "#         row_data = {\n",
    "#             'Rounding_Decimals': rounding_decimal,\n",
    "#             'Recall@100': noise_recall['Recall@100'],\n",
    "#             'Recall@1000': noise_recall['Recall@1000']\n",
    "#         }\n",
    "#         writer.writerow(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PSIRetrievalExactSearch is parent class for any model we are using for our experiement that can be used for retrieval\n",
    "# # Abstract class is BaseSearch\n",
    "# class PSIRetrievalExactSearch(BaseSearch):\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             model,\n",
    "#             path_corpus_embeddings: str = \"datasets/subquora/corpus_embeddings.pkl\",\n",
    "#             path_query_embeddings: str = \"datasets/subquora/query_embeddings.pkl\",\n",
    "#             **kwargs):\n",
    "#         #model is class should do nothing\n",
    "#         self.model = model\n",
    "#         self.path_corpus_embeddings = path_corpus_embeddings\n",
    "#         self.path_query_embeddings = path_query_embeddings\n",
    "#         self.show_progress_bar = kwargs.get(\"show_progress_bar\", True)\n",
    "#         self.convert_to_tensor = kwargs.get(\"convert_to_tensor\", True)\n",
    "#         self.results = {}\n",
    "\n",
    "#         logger.info(\"Load in Encoded Queries and Corpus from Pickle...\")\n",
    "#         # Verify file existence\n",
    "#         if not os.path.exists(self.path_corpus_embeddings):\n",
    "#             raise FileNotFoundError(f\"File '{self.path_corpus_embeddings}' not found.\")\n",
    "#         if not os.path.exists(self.path_query_embeddings):\n",
    "#             raise FileNotFoundError(f\"File '{self.path_query_embeddings}' not found.\")\n",
    "\n",
    "#         with open(self.path_query_embeddings, \"rb\") as f:\n",
    "#             self.query_embeddings = pickle.load(f)\n",
    "\n",
    "#         with open(self.path_corpus_embeddings, \"rb\") as f:\n",
    "#             self.corpus_embeddings = pickle.load(f)\n",
    "\n",
    "#     def add_rounding(self, rounding_decimal: int) -> None:\n",
    "#         # rounding decimal\n",
    "#         if rounding_decimal < 12:\n",
    "#             logger.info(\"Rounding decimal places of Queries and Corpus...\")\n",
    "#             for key, value in self.query_embeddings.items():\n",
    "#                 self.query_embeddings[key] = np.round(value, decimals=rounding_decimal)\n",
    "\n",
    "#             for key, value in self.corpus_embeddings.items():\n",
    "#                 self.corpus_embeddings[key] = np.round(value, decimals=rounding_decimal)\n",
    "\n",
    "#     def add_noise(self, rounding_decimal: int) -> None:\n",
    "#         logger.info(\"Adding Noise to Queries and Corpus...\")\n",
    "#         for key, value in self.query_embeddings.items():\n",
    "#             self.query_embeddings[key] += np.random.random() / 10**rounding_decimal\n",
    "\n",
    "#         for key, value in self.corpus_embeddings.items():\n",
    "#             self.corpus_embeddings[key] += np.random.random() / 10**rounding_decimal\n",
    "\n",
    "#     def search(self,\n",
    "#                corpus: Dict[str, Dict[str, str]],\n",
    "#                queries: Dict[str, str],\n",
    "#                top_k: int,\n",
    "#                score_function: str,\n",
    "#                return_sorted: bool = False,\n",
    "#                **kwargs) -> Dict[str, Dict[str, float]]:\n",
    "\n",
    "#         query_ids = list(self.query_embeddings.keys())\n",
    "#         self.results = {qid: {} for qid in query_ids}\n",
    "\n",
    "#         corpus_set = set(self.corpus_embeddings)\n",
    "#         query_set = set(self.query_embeddings)\n",
    "#         overlap = query_set.intersection(corpus_set)\n",
    "\n",
    "\n",
    "#         for qid in overlap:\n",
    "#             for score, corpus_id in overlap[qid]:\n",
    "#                 self.results[qid][corpus_id] = 1\n",
    "\n",
    "#         return self.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PSIRetrievalExactSearch(\n",
    "    beir_sbert,\n",
    "    path_corpus_embeddings = \"datasets/subquora/corpus_embeddings_full.pkl\",\n",
    "    path_query_embeddings= \"datasets/subquora/query_embeddings_full.pkl\") # This can go outside the loop\n",
    "\n",
    "print(\"here\")\n",
    "with open(\"datasets/subquora/qrels_full.json\", \"r\") as f:\n",
    "    qrels = json.load(f)\n",
    "\n",
    "with open(\"datasets/subquora/query_embeddings_full.pkl\", \"rb\") as f:\n",
    "    query_embeddings = pickle.load(f)\n",
    "\n",
    "with open(\"datasets/subquora/corpus_embeddings_full.pkl\", \"rb\") as f:\n",
    "    corpus_embeddings = pickle.load(f)\n",
    "\n",
    "\n",
    "rounding_recalls_PSI = []\n",
    "rounding_decimals = range(12,-1,-1)\n",
    "for decimal in rounding_decimals:\n",
    "    print(decimal, type(decimal))\n",
    "    model.add_rounding(decimal)\n",
    "    print(\"after add_rounding\")\n",
    "    retriever = EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "    print(\"after EvaluateRetrieval\")\n",
    "    # print(model.corpus_embeddings, model.query_embeddings)\n",
    "    # issue maybe you have to pass the correct corpus and queries in\n",
    "    results = retriever.retrieve(corpus_embeddings, query_embeddings)\n",
    "    print(\"after retrieve\")\n",
    "    ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "    print(\"decimal_places:\", decimal , ndcg, _map, recall, precision )\n",
    "    #recall@100 matters mostr, save to array for plotting\n",
    "    rounding_recalls_PSI.append(recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_recalls_PSI = []\n",
    "noise_decimals = range(12,-1,-1)\n",
    "for decimal in range(12,-1,-1):\n",
    "    # print(decimal, type(decimal))\n",
    "    model.add_noise(decimal)\n",
    "    # model.noise()\n",
    "    retriever = EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "    results = retriever.retrieve(model.corpus_embeddings, model.query_embeddings)\n",
    "    ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "    print(\"noise decimal:\", decimal , ndcg, _map, recall, precision )\n",
    "    noise_recalls_PSI.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Headers for CSV file\n",
    "headers = ['Rounding_Decimals', 'Recall@100', 'Recall@1000']\n",
    "\n",
    "# Create and write data to CSV file\n",
    "with open('results/PSI_rounding_recalls_full.csv', 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for rounding_decimal, rounding_recall in zip(rounding_decimals, rounding_recalls_PSI):\n",
    "        row_data = {\n",
    "            'Rounding_Decimals': rounding_decimal,\n",
    "            'Recall@100': rounding_recall['Recall@100'],\n",
    "            'Recall@1000': rounding_recall['Recall@1000']\n",
    "        }\n",
    "        writer.writerow(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers for CSV file\n",
    "headers = ['Rounding_Decimals', 'Recall@100', 'Recall@1000']\n",
    "\n",
    "# Create and write data to CSV file\n",
    "with open('results/PSI_noise_recall_full.csv', 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for rounding_decimal, noise_recall in zip(rounding_decimals, noise_recalls_PSI):\n",
    "        row_data = {\n",
    "            'Rounding_Decimals': rounding_decimal,\n",
    "            'Recall@100': noise_recall['Recall@100'],\n",
    "            'Recall@1000': noise_recall['Recall@1000']\n",
    "        }\n",
    "        writer.writerow(row_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
