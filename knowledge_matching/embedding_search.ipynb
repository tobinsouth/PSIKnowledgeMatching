{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is going to use BEIR to download a dataset and create embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. embeddings, saving & loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "DATASET = \"quora\"\n",
    "sbert_model_name = \"msmarco-distilbert-base-tas-b\"\n",
    "device = \"cpu\" # cuda for gpu usage\n",
    "k_queries = 1000\n",
    "k_documents = 5050000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from time import time\n",
    "from beir import util\n",
    "from beir_reengineered import NewSentenceBERT\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "import os, json, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Download nfcorpus.zip dataset and unzip the dataset\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(DATASET)\n",
    "out_dir = \"datasets\"\n",
    "data_path = util.download_and_unzip(url, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from time import time\n",
    "from beir import util\n",
    "from beir_reengineered import NewSentenceBERT\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "import os, json, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Download nfcorpus.zip dataset and unzip the dataset\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(DATASET)\n",
    "out_dir = \"datasets\"\n",
    "data_path = util.download_and_unzip(url, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522931/522931 [00:17<00:00, 29906.15it/s]\n"
     ]
    }
   ],
   "source": [
    "#### Provide the data path where nfcorpus has been downloaded and unzipped to the data loader\n",
    "# data folder would contain these files:\n",
    "# (1) nfcorpus/corpus.jsonl  (format: jsonlines)\n",
    "# (2) nfcorpus/queries.jsonl (format: jsonlines)\n",
    "# (3) nfcorpus/qrels/test.tsv (format: tsv (\"\\t\"))\n",
    "\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dense Retrieval using SBERT (Sentence-BERT) ####\n",
    "#### Provide any pretrained sentence-transformers model\n",
    "#### The model was fine-tuned using cosine-similarity.\n",
    "#### Complete list - https://www.sbert.net/docs/pretrained_models.html\n",
    "\n",
    "beir_sbert = NewSentenceBERT(sbert_model_name, device=device)\n",
    "model = DRES(beir_sbert, batch_size=256, corpus_chunk_size=512*9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25125/1462906915.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mqrels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mqid\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqrels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mqid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset_of_queries\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrue_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mqid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqrels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqrels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfalse_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdocid\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrue_documents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msubset_of_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_documents\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mfalse_documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mdocid\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset_of_corpus\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "# Create sub-sample\n",
    "subset_of_queries = random.sample(queries.keys(), k_queries)\n",
    "queries = {qid: queries[qid] for qid in subset_of_queries}\n",
    "qrels = {qid: qrels[qid] for qid in subset_of_queries}\n",
    "true_documents = set([docid for qid in qrels for docid in qrels[qid]])\n",
    "false_documents = set(random.sample(list(set([docid for docid in corpus if docid not in true_documents])), k_documents))\n",
    "subset_of_corpus = true_documents | false_documents\n",
    "corpus = {docid: corpus[docid] for docid in subset_of_corpus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode queries\n",
    "queries_l = [queries[qid] for qid in queries]\n",
    "query_embeddings = model.model.encode_queries(\n",
    "    queries_l,\n",
    "    batch_size=model.batch_size,\n",
    "    show_progress_bar=model.show_progress_bar,\n",
    "    convert_to_tensor=model.convert_to_tensor\n",
    ").cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode documents\n",
    "corpus_ids = sorted(corpus, key=lambda k: len(corpus[k].get(\"title\", \"\") + corpus[k].get(\"text\", \"\")), reverse=True)\n",
    "corpus_l = [corpus[cid] for cid in corpus_ids]\n",
    "sub_corpus_embeddings = model.model.encode_corpus(\n",
    "    corpus_l,\n",
    "    batch_size=model.batch_size,\n",
    "    show_progress_bar=model.show_progress_bar,\n",
    "    convert_to_tensor=model.convert_to_tensor\n",
    ").cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as new dataset\n",
    "os.makedirs(\"datasets/subquora/qrels\", exist_ok=True)\n",
    "with open(\"datasets/subquora/queries.jsonl\", \"w\") as f:\n",
    "    f.writelines([json.dumps({\"_id\": qid, \"text\": queries[qid], \"metadata\":{}})+\"\\n\" for qid in queries])\n",
    "with open(\"datasets/subquora/corpus.jsonl\", \"w\") as f:\n",
    "    f.writelines([json.dumps({\"_id\": docid, \"title\": corpus[docid].get(\"title\"), \"text\": corpus[docid].get(\"text\"), \"metadata\":{}})+\"\\n\" for docid in corpus])\n",
    "with open(\"datasets/subquora/qrels/test.tsv\", \"w\") as f:\n",
    "    f.write(\"query-id\\tcorpus-id\\tscore\\n\")\n",
    "    for qid in qrels:\n",
    "        for docid in qrels[qid]:\n",
    "            f.write(\"{}\\t{}\\t{}\\n\".format(qid, docid, qrels[qid][docid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save embeddings\n",
    "corpus_embeddings_dict = dict(zip(corpus_ids, sub_corpus_embeddings))\n",
    "query_embeddings_dict = dict(zip(queries.keys(), query_embeddings))\n",
    "import pickle\n",
    "\n",
    "with open(\"datasets/subquora/corpus_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(corpus_embeddings_dict, f)\n",
    "with open(\"datasets/subquora/query_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(query_embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # List files in the directory\n",
    "# files = os.listdir(\"datasets/subquora\")\n",
    "\n",
    "# # Check if the file is in the list\n",
    "# if \"query_embeddings.pkl\" in files:\n",
    "#     print(\"File found in directory.\")\n",
    "# else:\n",
    "#     print(\"File not found in directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"datasets/subquora/corpus_embeddings.pkl\", \"rb\") as f:\n",
    "#         corpus_embeddings_test = pickle.load(f)\n",
    "#         print(type(corpus_embeddings_test))\n",
    "# corpus_embeddings_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"datasets/subquora/query_embeddings.pkl\", \"rb\") as f:\n",
    "#         query_embeddings_test = pickle.load(f)\n",
    "#         print(type(query_embeddings_test))\n",
    "# query_embeddings_test\n",
    "# <class 'dict'>\n",
    "# {'148989': array([-5.42879179e-02, -1.91017106e-01, -1.20709697e-02,  2.05447242e-01,\n",
    "#          4.04155254e-01,  2.48869240e-01, -4.52450693e-01,  1.38501331e-01,\n",
    "#         -2.10237205e-01, -1.51516631e-01,  4.76916820e-01,  3.10554087e-01,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_embeddings_test\n",
    "# # query_ids = list(query_embeddings_test.keys())\n",
    "# # print(query_ids)\n",
    "# # corpus_ids = sorted(query_ids, reverse=True)\n",
    "# # corpus_ids\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# max_decimal_places = 0\n",
    "\n",
    "# for key, array in query_embeddings_test.items():\n",
    "#     for element in array:\n",
    "#         decimal_places = len(str(element).split('.')[1])\n",
    "#         if decimal_places > max_decimal_places:\n",
    "#             max_decimal_places = decimal_places\n",
    "\n",
    "# print(\"Maximum number of decimal places:\", max_decimal_places) # Maximum number of decimal places: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. (only sometimes) round embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir.retrieval.search import BaseSearch # type: ignore beir/retrieval/search/dense/exact_search.py\n",
    "from beir.util import cos_sim #beir/util.py\n",
    "import torch # type: ignore\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import heapq\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExperiementRetrievalExactSearch is parent class for any model we are using for our experiement that can be used for retrieval\n",
    "# Abstract class is BaseSearch\n",
    "class ExperiementRetrievalExactSearch(BaseSearch):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            rounding_decimal: int = 16,\n",
    "            path_corpus_embeddings: str = \"datasets/subquora/corpus_embeddings.pkl\",\n",
    "            path_query_embeddings: str = \"datasets/subquora/query_embeddings.pkl\",\n",
    "            **kwargs):\n",
    "        #model is class should do nothing\n",
    "        self.model = model\n",
    "        self.rounding_decimal = rounding_decimal\n",
    "        self.path_corpus_embeddings = path_corpus_embeddings\n",
    "        self.path_query_embeddings = path_query_embeddings\n",
    "        self.show_progress_bar = kwargs.get(\"show_progress_bar\", True)\n",
    "        self.convert_to_tensor = kwargs.get(\"convert_to_tensor\", True)\n",
    "        self.results = {}\n",
    "\n",
    "        logger.info(\"Load in Encoded Queries and Corpus from Pickle...\")\n",
    "        # Verify file existence\n",
    "        if not os.path.exists(self.path_corpus_embeddings):\n",
    "            raise FileNotFoundError(f\"File '{self.path_corpus_embeddings}' not found.\")\n",
    "        if not os.path.exists(self.path_query_embeddings):\n",
    "            raise FileNotFoundError(f\"File '{self.path_query_embeddings}' not found.\")\n",
    "\n",
    "        with open(self.path_query_embeddings, \"rb\") as f:\n",
    "            self.query_embeddings = pickle.load(f)\n",
    "\n",
    "        with open(self.path_corpus_embeddings, \"rb\") as f:\n",
    "            self.corpus_embeddings = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "    def round(self, rounding_decimal: int):\n",
    "        # rounding decimal\n",
    "        self.rounding_decimal = rounding_decimal\n",
    "        if rounding_decimal < 16:\n",
    "            logger.info(\"Rounding decimal places of Queries and Corpus...\")\n",
    "            for key, value in self.query_embeddings.items():\n",
    "                self.query_embeddings[key] = np.round(value, decimals=rounding_decimal)\n",
    "\n",
    "            for key, value in self.corpus_embeddings.items():\n",
    "                self.corpus_embeddings[key] = np.round(value, decimals=rounding_decimal)\n",
    "\n",
    "    def search(self,\n",
    "               corpus: Dict[str, Dict[str, str]],\n",
    "               queries: Dict[str, str],\n",
    "               top_k: int,\n",
    "               score_function: str,\n",
    "               return_sorted: bool = False,\n",
    "               **kwargs) -> Dict[str, Dict[str, float]]:\n",
    "        # Create embeddings for all queries using model.encode_queries()\n",
    "        # Runs semantic search against the corpus embeddings\n",
    "        # Returns a ranked list with the corpus ids\n",
    "\n",
    "        query_ids = list(self.query_embeddings.keys())\n",
    "        self.results = {qid: {} for qid in query_ids}\n",
    "\n",
    "\n",
    "        logger.info(\"Sorting Corpus by document length (Longest first)...\")\n",
    "        corpus_ids = sorted(list(self.corpus_embeddings.keys()), reverse=True)\n",
    "\n",
    "        result_heaps = {qid: [] for qid in query_ids}  # Keep only the top-k docs for each query\n",
    "\n",
    "        # Convert dictionary values to PyTorch tensors\n",
    "        corpus_tensors = [torch.tensor(embedding) for embedding in self.corpus_embeddings.values()]\n",
    "        query_tensors = [torch.tensor(embedding) for embedding in self.query_embeddings.values()]\n",
    "        # Stack tensors along a new dimension (batch dimension)\n",
    "        corpus_embeddings_tensor = torch.stack(corpus_tensors)\n",
    "        query_embeddings_tensor = torch.stack(query_tensors)\n",
    "\n",
    "        # Compute similarites using  cosine-similarity\n",
    "        cos_scores = cos_sim(query_embeddings_tensor, corpus_embeddings_tensor)\n",
    "        cos_scores[torch.isnan(cos_scores)] = -1\n",
    "\n",
    "        # Get top-k values\n",
    "        cos_scores_top_k_values, cos_scores_top_k_idx = torch.topk(cos_scores, min(top_k+1, len(cos_scores[1])), dim=1, largest=True, sorted=return_sorted)\n",
    "        cos_scores_top_k_values = cos_scores_top_k_values.cpu().tolist()\n",
    "        cos_scores_top_k_idx = cos_scores_top_k_idx.cpu().tolist()\n",
    "\n",
    "        for query_itr in range(len(query_embeddings_tensor)):\n",
    "            query_id = query_ids[query_itr]\n",
    "            for sub_corpus_id, score in zip(cos_scores_top_k_idx[query_itr], cos_scores_top_k_values[query_itr]):\n",
    "                corpus_id = corpus_ids[sub_corpus_id]\n",
    "                if corpus_id != query_id:\n",
    "                    if len(result_heaps[query_id]) < top_k:\n",
    "                        # Push item on the heap\n",
    "                        heapq.heappush(result_heaps[query_id], (score, corpus_id))\n",
    "                    else:\n",
    "                        # If item is larger than the smallest in the heap, push it on the heap then pop the smallest element\n",
    "                        heapq.heappushpop(result_heaps[query_id], (score, corpus_id))\n",
    "\n",
    "        for qid in result_heaps:\n",
    "            for score, corpus_id in result_heaps[qid]:\n",
    "                self.results[qid][corpus_id] = score\n",
    "\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load the SBERT model and retrieve using cosine-similarity\n",
    "model = ExperiementRetrievalExactSearch(beir_sbert)\n",
    "retriever = EvaluateRetrieval(model, score_function=\"cos_sim\") # or \"cos_sim\" for cosine similarity\n",
    "results = retriever.retrieve(corpus, queries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Evaluate your model with NDCG@k, MAP@K, Recall@K and Precision@K  where k = [1,3,5,10,100,1000]\n",
    "ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "print(ndcg, _map, recall, precision )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExperiementRetrievalExactSearch(beir_sbert) # This can go outside the loop\n",
    "for decimal in range(12,-1,-1):\n",
    "    # print(decimal, type(decimal))\n",
    "    model.round(decimal)\n",
    "    # model.noise()\n",
    "    retriever = EvaluateRetrieval(model, score_function=\"cos_sim\") # or \"cos_sim\" for cosine similarity\n",
    "    results = retriever.retrieve(corpus, queries)\n",
    "    ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "    print(\"decimal_places:\", decimal , ndcg, _map, recall, precision )\n",
    "    #recall@100 matters mostr, save to array for plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentence_trans_venv",
   "language": "python",
   "name": "sentence_trans_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
